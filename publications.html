<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Info</div>
<div class="menu-item"><a href="index.html">Main</a></div>
<div class="menu-item"><a href="bio.html">Short&nbsp;bio</a></div>
<div class="menu-item"><a href="publications/CV_Misiakiewicz.pdf">CV</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks/Slides</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="teaching.html">List</a></div>
<div class="menu-item"><a href="SDS659.html">S&amp;DS&nbsp;659</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<p>This page is irregularly updated! Here is a link to my <a href="https://scholar.google.com/citations?user=E8Jst30AAAAJ&amp;hl=en">google scholar account</a>.</p>
<p><b>Preprints:</b></p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2403.08938">A non-asymptotic theory of Kernel Ridge Regression: deterministic equivalents, test error, and GCV estimator</a>. T. Misiakiewicz, B. Saeed. Preprint, 2024.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2403.08160">Asymptotics of random feature regression beyond the linear scaling regime</a>. H. Hu, YM. Lu, T. Misiakiewicz. Preprint, 2024.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2204.10425.pdf">Spectrum of inner-product kernel matrices in the polynomial regime and multiple descent phenomenon in kernel ridge regression</a>. T. Misiakiewicz. Preprint, 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2103.15996.pdf">Minimum complexity interpolation in random features models</a>. M. Celentano, T. Misiakiewicz, A. Montanari. Preprint, 2021.</p>
</li>
</ul>
<p><b>Conferences:</b></p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2407.05622">On the complexity of learning sparse functions with statistical and gradient queries</a>. N. Joshi, T. Misiakiewicz, N. Srebro. NeurIPS, 2024.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2405.15699">Dimension-free deterministic equivalents and scaling laws for random feature regression</a>. L. Defilippis, B. Loureiro, T. Misiakiewicz. NeurIPS, 2024.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2302.11055.pdf">SGD learning on neural networks: leap complexity and saddle-to-saddle dynamics</a>. E. Abbe, E. Boix-Adsera, T. Misiakiewicz. Conference of Learning Theory (COLT) 2023.</p>
</li>
</ul>
<ul>
<li><p><a href="https://">Precise Learning Curves and Higher-Order Scalings for Dot-product Kernel Regression</a>. L. Xiao, J. Pennington, T. Misiakiewicz, H. Hu, Y. M. Lu. NeurIPS, 2022. (Merged with <a href="https://arxiv.org/pdf/2204.10425.pdf">paper</a>)</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2111.08308.pdf">Learning with convolution and pooling operations in kernel methods</a>. T. Misiakiewicz, S. Mei. NeurIPS, 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2202.08658.pdf">The merged-staircase property: a necessary and nearly sufficient condition for SGD learning of sparse functions on two-layer neural networks</a>. E. Abbe, E. Boix-Adsera, T. Misiakiewicz. Conference of Learning Theory (COLT) 2022.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2102.13219.pdf">Learning with invariances in random features and kernel models</a>. S. Mei, T. Misiakiewicz, A. Montanari. Conference of Learning Theory (COLT) 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/2006.13409.pdf">When do Neural Networks Outperform Kernel Methods?</a> B. Ghorbani, S. Mei, T. Misiakiewicz, A. Montanari. NeurIPS, 2020.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1906.08899.pdf">Limitations of Lazy Training of Two-layers Neural Networks</a> B. Ghorbani, S. Mei, T. Misiakiewicz, A. Montanari. NeurIPS, 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1902.06015.pdf">Mean-field theory of two-layers neural networks: dimension-free bounds and kernel limit</a>. S. Mei, T. Misiakiewicz, A. Montanari. Conference of Learning Theory (COLT) 2019.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1703.08729.pdf">Solving SDPs for synchronization and MaxCut problems via the Grothendieck inequality</a>. S. Mei, T. Misiakiewicz, A. Montanari. Conference of Learning Theory (COLT) 2017.</p>
</li>
</ul>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/iel7/7444067/7446973/07446993.pdf">Concentration to zero bit-error probability for regular LDPC codes on the binary symmetric channel: Proof by loop calculus</a>. M. Vuffray, T. Misiakiewicz. Proceedings of the 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton, 2015).     </p>
</li>
</ul>
<p><b>Journals:</b></p>
<ul>
<li><p><a href="https://arxiv.org/pdf/2308.13431">Six lectures on linearized neural networks</a>. T. Misiakiewicz, A. Montanari. Journal of Statistical Mechanics: Theory and Experiment, 2024.</p>
</li>
</ul>
<ul>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S1063520321001044">Generalization error of random features and kernel methods: hypercontractivity and kernel matrix concentration</a>. S. Mei, T. Misiakiewicz, A. Montanari. Applied and Computational Harmonic Analysis, Vol 59, 3-84, <a href="https://www.sciencedirect.com/journal/applied-and-computational-harmonic-analysis/vol/59/suppl/C">Special Issue on Harmonic Analysis and Machine Learning</a>, 2022. <a href="https://arxiv.org/pdf/2101.10588.pdf">(arXiv)</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://iopscience.iop.org/article/10.1088/1742-5468/ac3a81/meta">When do Neural Networks Outperform Kernel Methods?</a> B. Ghorbani, S. Mei, T. Misiakiewicz, A. Montanari. Journal of Statistical Mechanics: Theory and Experiment, Volume December 2021.</p>
</li>
</ul>
<ul>
<li><p><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-2/Linearized-two-layers-neural-networks-in-high-dimension/10.1214/20-AOS1990.full">Linearized two-layers neural networks in high dimension</a>. B. Ghorbani, S. Mei, T. Misiakiewicz, A. Montanari. Annals of Statistics, Vol 49, 1029-1054, April 2021. <a href="https://arxiv.org/pdf/1904.12191.pdf">(arXiv)</a></p>
</li>
</ul>
<ul>
<li><p><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-4/Discussion-of--Nonparametric-regression-using-deep-neural-networks-with/10.1214/19-AOS1910.full">Discussion of:“Nonparametric regression using deep neural networks with ReLU activation function”</a>. B. Ghorbani, S. Mei, T. Misiakiewicz, A. Montanari. Annals of Statistics, volume 48, 1898-1901 (2020).</p>
</li>
</ul>
<p><b>Undergraduate and graduate work:</b>  </p>
<ul>
<li><p><a href="https://searchworks.stanford.edu/view/14782661">Learning with neural networks in high dimensions</a>. T. Misiakiewicz. PhD Dissertation from Stanford University, Statistics Department, 2023.  This work received the Theodore W. Anderson Theory of Statistics Award, Stanford University.</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/pdf/1509.06893.pdf">Efficient reconstruction of transmission probabilities in a spreading process from partial observations</a>. A. Lokhov, T. Misiakiewicz. Preprint, 2015.</p>
</li>
</ul>
<ul>
<li><p><a href="publications/M2HiggsCMS_misiakiewicz.pdf">Estimation du bruit de fond reductible par la méthode SS dans le canal de desintegration du boson de Higgs en 4 leptons</a>. T. Misiakiewicz. Master Thesis (2016). <a href="http://llr.in2p3.fr">Laboratoire Leprince-Ringuet (LLR)</a>. <a href="https://home.cern/science/experiments/cms">CMS experiment at the Large Hadron Collider (LHC)</a>, Geneva.</p>
</li>
</ul>
<ul>
<li><p><a href="publications/M1GraphicalModels_misiakiewicz.pdf">Application of Graphical Models to Decoding and Machine Learning</a>. T. Misiakiewicz. Work done at <a href="https://cnls.lanl.gov/External/">Center for Linear-Studies (CNLS)</a> at <a href="https://www.lanl.gov">Los Alamos National Laboratory (LANL)</a>, New Mexico, 2015.</p>
</li>
</ul>
<ul>
<li><p><a href="publications/L3MassiveGravity_misiakiewicz.pdf">Ondes gravitationnelles en theorie de la gravite massive</a>. T. Misiakiewicz. <a href="http://www.apc.univ-paris7.fr/APC_CS/">Astroparticle and Cosmology Laboratory (APC)</a>, Cosmology and Gravitation theory group. Advisor: Prof. Daniele Steer (2014).</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
